---
title: "Estimating the effect of local police violence on mobility modality in Illinois"
author: "Taylor Alarcon"
output: html_notebook
---

# Abstract
I use data from the U.S. Census and MappingPoliceViolence.org to estimate the causal effect that local police violence has on mobility modality across neighborhoods in Illinois. I employ propensity score matching to match census tracts on a variety of demographic and economic covariates, assign exposure to fatal police violence as the treatment, and estimate the average treatment effect on the treated (ATT), where the outcome variable is percentage of citizens either driving, walking, taking public transit, etc. to work. My findings insist that exposure to local police violence causes a %2.5 decrease in citizens who drive to work and a %2 increase in citizen population who take public transit to work, building on theory that local violence -- police violence in particular -- have substantial impacts on collective fear, anxiety, and distrust in exposed populations.

# Motivation
Does exposure to police violence cause changes in urban mobility? 

There exists a body of work that looks at the causal relationship between one’s exposure to violence and one’s social behavior. A 2016 study in the Journal of Research in Crime and Delinquency examined the association between witnessing community violence and criminal behavior in a representative sample of young adults, finding that recent exposure to violence in the community increased the risk for young adult criminal activity, while another 2012 study tangentially suggestsed the negative impact that local violence has on psychological distress, attention span, and impulse control. These past studies suggest that exposure to violence in general, let alone violence conducted by those meant to serve and protect, may have some sort of causal relationship with one’s likelihood to engage in different social behaviors.

While past research suggests that exposure to violence has a potential association with anti-social behavior, there is currently no research that looks specifically at how police violence affects how citizens move through their communities, to go to places like work, church, or other spaces. This project seeks to understand inequality based not on where people live, but where and how they move about the city. Building on past research on mobility disadvantage, it examines separation, isolation, and integration for communities exposed vs. not exposed to local acts of fatal police violence.

# Data
The two datasets I decided to use for this analysis are [MappingPoliceViolence.org]("https://mappingpoliceviolence.org/) and [U.S. Census Demographic Data]("https://www.kaggle.com/datasets/muonneutrino/us-census-demographic-data/data") (Kaggle). I am using the data from MPV to collect a list of census tracts in Illinois that have experienced at least one instance of local police violence, i.e., exposure to what I refer to as the treatment. Based on this list of exposed census tracts, I then added a column to the U.S. demographic dataset -- where each observation is a census tract and its corresponding demographic and economic information - with a dummy variable, where 1 denotes having been exposed to police violence and 0 denotes no exposure.

This final combined data structure has variables such as gender and racial compositions, income dynamics, poverty and employment rates, and mobility measures for each census tract in the U.S. Because I am only performing this analysis on Illinois, I subset this final dataset to only include Illinois census tracts. There are over 3,000 census tracts in Illinois and, according to MPV, 141 instances of police violence through the year 2017.

My outcome variable(s) are any variables that have to do with mobility (driving, walking, or taking public transit to work). My treatment variable is whether or not that census tract has been exposed to local police violence.My explanatory variables (and confounders) are everything else: gender and racial compositions, income dynamics, poverty and employment rates, and all other pre-treatment variables included in the U.S. Census Demographic Dataset.

I include some data visualizations and descriptive statistics in Data Wrangling and Analysis section of the paper. 

# Method: Propensity score matching

Propensity scores are a one-number summary of all your covariates. In ordinary terms, propensity score for an observation is generated by summarizing all the other data on that observation. Propensity score matching is the process of identifying incredibly similar observations in a way that artificially constructs treatment and control groups to estimate the treatment effect, getting as close as possible to a randomized experiment.

Most often, propensity score matching is implemented via a statistical package that can be loaded in software, but it can also be hard-coded by (1) defining the variables for each observation in the dataset that are confounders, (2) denoting which observations have been treated vs. those that haven't, (3) using logistic regression to predict, for each observation, the propensity to receive the treatment. This prediction is the propensity score: the probability of having received the treatment. 

Once these steps are taken, the researcher can match observations that received the treatment with similar observations (i.e., similar propensity scores, or similar summary of their covariates) that have not received the treatment, restructure the dataset to include the matched data only, check to ensure the major assumptions (overlap and balance, which are included below), and estimate -- either via difference in means or via regression -- the effect of the treatment on the outcome of interest.

A few benefits of propensity score matching include being able to adjust for one variable instead of many, requiring less strict parametric assumptions, reasonably addressable diagnostics, that it can be incorporated into a doubly-robust strategy for causal inference, and that it the researcher can choose the model specification without ever looking at an outcome. 

Costs, on the other hand, include the time commitment, the need for a decent estimate of the propensity score, lack of clear guidelines for success, and vulnerability to p-hacking.

# Estimands

Given the nature of the research question, structure of the data, and method, I found it most appropriate to estimate average treatment for the treated (ATT) in this analysis. I am making inferences solely about census tracts that have been exposed to the treatment, i.e., census tracts that have experienced local instances of police violence.

The average treatment effect on the treated (ATT) is defined as the average treatment effect of observations that were defined as treated. In mathematical terms and using the Potential Outcomes Framework, this can be defined as E(Y(1)-Y(0)|Z=1). ATT generally makes the most sense for propensity score matching given that matching fundamentally restricts the dataset to observations that are matches. The researcher can only reasonably make inferences about the treated observations, since non-treated observations who are not similar to treated observations are thrown out from the sample.

# Assumptions

The assumptions for propensity score matching include the two standard methods for all causal inference problems -- ignorability and SUTVA -- as well as sufficient balance and overlap.

Ignorability: the ignorability of the treatment assignment says that if you can’t control for confounders, your statistical model is showing correlation and not causation; if the factors that determine treatment assignment are observable, we can control for them in order to obtain causal effects.

Sufficient overlap: Enough observations with similarities between groups (enough matches).

Appropriate specification of the propensity score model/ balance achieved: Low standard mean differences and other statistics of difference, and enough observations that there is a sufficient number of both treated and control observations (low number of unmatched units).

SUTVA: that response of a particular unit depends only on the treatment to which the observation was assigned (no alternative explanations for affecting the outcome) and does not affect the outcome of any other observations.

The plausibility of the assumptions under the current research design is high. Ignorability is plausible given that we can control for all observable factors that determine treatment assignment, and SUTVA is plausible since census tract data points are fundamentally bounded. Overlap and balance are also plausible given the volume of census tracts in the entire sample, the diversity of tract demographics across the state of Illinois, and overlapping covariate characteristics between observations.


# Data Wrangling and Analysis
```{r}
### Load libraries
library(tidyverse)
library(haven) # for reading dta files
library(lubridate) # for datetime
library(tigris) # for census data
library(sf) # for spatial data
library(tidycensus) # census api
library(MatchIt) # for pscore matching
library(broom)
```


```{r}
### Load datasets
# Mapping Police Violence data
mpv_raw <- read_csv("/Users/taylor/Desktop/phd/research-local/data/police-violence-data/MPV03282023.csv")

# US Census Tract Demographics dataset from Kaggle
census_tract_demographics_raw <- read.csv("/Users/taylor/Desktop/phd/research-local/data/housing-neighborhoods/us-census-tracts/kaggle census tract demographic data/acs2017_census_tract_data.csv")
```


```{r}
### Clean up MPV data to be up to 2017, since the Census data only goes up to 2017 
mpv_raw$date <- as.Date(mpv_raw$date, format = "%m/%d/%Y")
#mpv_raw$date
```


```{r}
mpv_2017 <- mpv_raw %>%
  filter(date < "2018-01-01")
```


```{r}
# Check sanity
dim(mpv_2017) # 5405 instances of fatal police violence nationwide up to 2017
min(mpv_2017$date) # 2012-04-07
max(mpv_2017$date) # Sanity check
```


```{r}
### Filtering MPV data to just Illinois
mpv_2017_il <- mpv_2017 %>%
  filter(state == "IL")
mpv_2017_il # 141 instances in IL
```

```{r}
## Now, filter census_tract dataset to only include IL, so that you can start matchin tagging census tracts with treatment
census_tracts_demographics_illinois <- census_tract_demographics_raw %>%
  filter(State == "Illinois")
```

```{r}
# Getting just latitude and longitude for instances in IL
mpv_2017_il_long_lat_only <- mpv_2017_il %>%
  select(longitude, latitude)
```


```{r}
### Loading IL shapefile from tidycensus API + point data geoprocessing

# Getting CA census tract data (shapefile) from the Census API, per tutorial link above
il <- tidycensus::get_acs(state = "IL", geography = "tract",
                          variables = "B19013_001", geometry = TRUE)

# Convert to sf object of points, so that we can match it to the shapefile above
mpv_2017_il_long_lat_sf <- mpv_2017_il_long_lat_only %>%
  filter(!is.na(latitude), !is.na(longitude)) %>% # get rid of NAs
  st_as_sf(coords = c("longitude", "latitude"), crs = st_crs(il)) # converting lat and long numbers to geometry object
```



### Visualization(s) & Descriptive Stats

```{r}
# Plot the sf object created above now that it's been geoprocessed
plot(mpv_2017_il_long_lat_sf)
```


```{r}
# Better visualization of the point data, overlaying CA shapefile 
ggplot(il) +
  geom_sf() +
  geom_sf(data = mpv_2017_il_long_lat_sf) +
  ggtitle("Mapping Police Violence in Illinois 2012-2017 
(141 observations)")
```
```{r}
# descriptive statistics for police violence data in illinois
mpv_2017_il %>%
  drop_na(age) %>%
  group_by(race) %>%
  summarize(average_age = mean(age),
            total_killings = n())
```
```{r}
# descriptive statics for U.S. Census tract data
census_tracts_demographics_illinois %>%
  drop_na() %>%
  group_by(County) %>%
  summarize(population_average = mean(TotalPop),
            men_average = mean(Men),
            black_average = mean(Black),
            white_average = mean(White),
            income_average = mean(Income))
```


```{r}
### Extracting the FIPS codes for Census Tracts where police violence occurred

# Variable for all CA census tracts -- retrieving from tidycensus api
il_tracts <- tracts("IL", class = "sf") %>%
  select(GEOID, TRACTCE)

# Creating boundaries around all CA census tracts
il_bbox <- st_bbox(il_tracts)
```


```{r}
# Use st_join to find intersections of point data and/within CA census tracts
il_points_tract <- st_join(mpv_2017_il_long_lat_sf, il_tracts) # spits out the tracts associated with the points 
il_points_tract # 953 observations since many Census Tract IDs are duplicates (multiple instances of police violence)
```


```{r}
# Create the dataframe to store all the fips codes for CA
tract_IDs_il <- c(il_points_tract$GEOID)
```


```{r}
length(tract_IDs_il) # 141 CA instances with census tracts
```


```{r}
length(unique(tract_IDs_il)) # 130 unique census tracts
```


```{r}
###  Final list of Census Tract IDs

# Remove duplicates for final list
tract_IDs_il_final <- c(unique(tract_IDs_il))
# Print final list
length(tract_IDs_il_final) # sanity check to make sure there's only 130
print(tract_IDs_il_final) # print Census Tract FIPS codes that experienced police violence through 2017
```


```{r}
# converting the column to a string
typeof(census_tracts_demographics_illinois$TractId) # to check the type
census_tracts_demographics_illinois$TractId <- as.character(census_tracts_demographics_illinois$TractId)
census_tracts_demographics_illinois$TractId[3] # sanity check
```


```{r}
# setting up the if_else statement for the treamtent

census_tracts_demographics_il_with_treatment <- census_tracts_demographics_illinois %>%
  mutate(mpv_treatment = if_else(TractId %in% tract_IDs_il_final, 1, 0))
```


```{r}
# take a look at the dataframe you've built
census_tracts_demographics_il_with_treatment
```

### Setting up framework for propensity score matching

Choosing confounders (all pre-treatment variables that aren't the outcome variable) and variables of interest
Variables to create new columns for: % men, % women, % voting age citizen:
```{r}
census_tracts_demographics_il_with_treatment_final <- census_tracts_demographics_il_with_treatment %>%
  mutate(perc_men = Men/TotalPop,
         perc_women = Women/TotalPop,
         perc_voting_age = VotingAgeCitizen/TotalPop)

census_tracts_demographics_il_with_treatment_final
```

Treatment = mpv_treatment
Dependent variable(s) = Mobility (Drive, Carpool, Transit, Walk, OtherTransp, WorkAtHome, MeanCommute)
Explanatory variables = perc_men, perc_women, Hispanic, White, Black, Native, Asian, Pacific, perc_voting_age, Income, IncomePerCap, Poverty, ChildPoverty, Professional, Service, Office, Construction, Production, Employed, PrivateWork, PublicWork, SelfEmployed, FamilyWork, Unemployment

```{r}
# creating a dataset with just these variables above so we can focus
pscore_dataset <- census_tracts_demographics_il_with_treatment_final %>%
  select(mpv_treatment,Drive, Carpool, Transit, Walk, OtherTransp, WorkAtHome, MeanCommute, perc_men, perc_women, Hispanic, White, Black, Native, Asian, Pacific, perc_voting_age, Income, IncomePerCap, Poverty, ChildPoverty, Professional, Service, Office, Construction, Production, Employed, PrivateWork, PublicWork, SelfEmployed, FamilyWork, Unemployment)

pscore_data_clean <- na.omit(pscore_dataset) # get rid of NAs so that you can run matchit
dim(pscore_data_clean) # 3105 vs.
```



## PScore analysis using MatchIt

Matching [parameters](https://www.rdocumentation.org/packages/MatchIt/versions/4.5.5/topics/matchit) to tune:
- method: nearest, optimal, full, exact
- distance: glm, mahalanobis

### Matching V1
```{r}
m.out1 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "nearest",
                  distance = "glm")

m.out1
summary(m.out1)
```
### Matching V2
```{r}
m.out2 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "optimal",
                  distance = "glm")

m.out2
summary(m.out2)
```

### Matching V3 - Best Performing Model
```{r}
m.out3 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "full",
                  distance = "glm")

m.out3
summary(m.out3)
```

### Matching V4
```{r}
m.out4 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "exact",
                  distance = "glm")

m.out4
summary(m.out4)
```

### Matching V5
```{r}
m.out5 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "nearest",
                  distance = "mahalanobis")

m.out5
summary(m.out5)
```
### Matching V6
```{r}
m.out6 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "optimal",
                  distance = "mahalanobis")

m.out6
summary(m.out6)
```

### Matching V7
```{r}
m.out7 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "full",
                  distance = "mahalanobis")

m.out7
summary(m.out7)
```

### Matching V8
```{r}
m.out8 <- matchit(mpv_treatment ~ perc_men + perc_women + Hispanic + White + Black + Native + Asian + Pacific + perc_voting_age + Income + IncomePerCap + Poverty + ChildPoverty + Professional + Service + Office + Construction + Production + Employed + PrivateWork + PublicWork + SelfEmployed + FamilyWork + Unemployment,
                  data = pscore_data_clean,
                  method = "exact",
                  distance = "mahalanobis")

m.out8
summary(m.out8)
```


# Diagnostics

The following diagnostic tests apply to Model 3, the best-performing model in terms of overlap and balance (low standard mean difference and standard pair difference).

### Visualizing overlap and balance
```{r}
plot(m.out3, type = "density", interactive = FALSE,
     which.xs = ~Black + White + perc_women + Unemployment + Income + Poverty)
```
```{r}
plot(summary(m.out3))
```
# Results

### Estimating the treatment effect on various mobility variables using regression with just the matched data

Reminders:
Treatment = mpv_treatment
Dependent variable(s) = Mobility (Drive, Carpool, Transit, Walk, OtherTransp, WorkAtHome, MeanCommute)
Explanatory variables = perc_men, perc_women, Hispanic, White, Black, Native, Asian, Pacific, perc_voting_age, Income, IncomePerCap, Poverty, ChildPoverty, Professional, Service, Office, Construction, Production, Employed, PrivateWork, PublicWork, SelfEmployed, FamilyWork, Unemployment

```{r}
# create dataframe from just matched data of model 3
matched_data_only <- match.data(m.out3)
```

### Drive -- matched data
```{r}
model_ps_match1 <- lm(Drive ~ mpv_treatment,
                data = matched_data_only,
                weights = weights) 
tidy(model_ps_match1)
```

### Carpool -- matched data
```{r}
model_ps_match2 <- lm(Carpool ~ mpv_treatment,
                data = matched_data_only,
                weights = weights) 
tidy(model_ps_match2)
```

### Transit -- matched data
```{r}
model_ps_match3 <- lm(Transit ~ mpv_treatment,
                data = matched_data_only,
                weights = weights) 
tidy(model_ps_match3)
```

### Walk -- matched data
```{r}
model_ps_match4 <- lm(Walk ~ mpv_treatment,
                data = matched_data_only,
                weights = weights) 
tidy(model_ps_match4)
```

### OtherTransp -- matched data
```{r}
model_ps_match5 <- lm(OtherTransp ~ mpv_treatment,
                data = matched_data_only,
                weights = weights) 
tidy(model_ps_match5)
```

### WorkAtHome -- matched data
```{r}
model_ps_match6 <- lm(WorkAtHome ~ mpv_treatment,
                data = matched_data_only,
                weights = weights) 
tidy(model_ps_match6)
```

### MeanCommute -- matched data
```{r}
model_ps_match7 <- lm(MeanCommute ~ mpv_treatment,
                data = matched_data_only,
                weights = weights) 
tidy(model_ps_match7)
```
### Drive -- standard linear regression
```{r}
lm1 <- lm(Drive ~ mpv_treatment,
                data = census_tracts_demographics_il_with_treatment_final) 
tidy(lm1)
```

### Carpool -- standard linear regression
```{r}
lm2 <- lm(Carpool ~ mpv_treatment,
                data = census_tracts_demographics_il_with_treatment_final) 
tidy(lm2)
```

### Transit -- standard linear regression
```{r}
lm3 <- lm(Transit ~ mpv_treatment,
                data = census_tracts_demographics_il_with_treatment_final) 
tidy(lm3)
```

### Walk -- standard linear regression
```{r}
lm4 <- lm(Walk ~ mpv_treatment,
                data = census_tracts_demographics_il_with_treatment_final) 
tidy(lm4)
```

### OtherTransp -- standard linear regression
```{r}
lm5 <- lm(OtherTransp ~ mpv_treatment,
                data = census_tracts_demographics_il_with_treatment_final) 
tidy(lm5)
```

### WorkAtHome -- standard linear regression
```{r}
lm6 <- lm(WorkAtHome ~ mpv_treatment,
                data = census_tracts_demographics_il_with_treatment_final) 
tidy(lm6)
```

### MeanCommute -- standard linear regression
```{r}
lm7 <- lm(MeanCommute ~ mpv_treatment,
                data = census_tracts_demographics_il_with_treatment_final) 
tidy(lm7)
```

# Discussion & limitations

The results above build on past theory on police violence, social behavior, and urban inequality. While unfortunately my results did not achieve statistical significance (they were close!), it validated the original hypothesis that local instances of police violence impact urban mobility patterns, which, as we know, may have impacts on work, family life, and other social and economic behavior.

Some benefits of propensity score matching include the fact that if we limit the data to observations with sufficient overlap and balance, we reduce potential bias in our inferences. An unfortunate limitation of propensity score matching is that it’s hard to know if ignorability — a crucial assumption for causal inference — is satisfied. 

Another limitation of the current analysis is not only that we throw away lots of observations that weren’t matched (in this case, thousands of observations), but we also only make inferences on one subset: the treated group. This may be helpful, but a limitation is not being able to make inferences about a larger population, i.e., all or most census tracts in the sample population. 

Still, reaching as unbiased of an estimate as possible of the treatment effect is necessary for making causal claims, even if lots of data is thrown away. Continuing research using propensity score matching to estimate causal effects on this topic would include employing sensitivity analysis and robustness checks for cases where ignorability doesn’t hold. This can strengthen our analysis, as well as using machine learning for principle component analysis to create even better balance and overlap for our matched data.


